#!/usr/bin/env node

/**
 * ä¸­æ–‡ä¼˜åŒ–AIæ¨¡å‹å®‰è£…è„šæœ¬
 * ä¸“é—¨å®‰è£…å’Œé…ç½®é€‚åˆä¸­æ–‡ç¼–ç¨‹çš„AIæ¨¡å‹
 */

import { execSync, spawn } from "child_process"
import { createWriteStream, existsSync } from "fs"
import { mkdir } from "fs/promises"

interface ChineseModel {
  name: string
  displayName: string
  description: string
  size: string
  sizeGB: number
  category: "lightweight" | "balanced" | "powerful"
  chineseOptimized: boolean
  codingCapability: "basic" | "good" | "excellent"
  priority: number
  recommended: boolean
  downloadUrl?: string
  requirements: {
    minRAM: number // GB
    minDisk: number // GB
    recommendedRAM: number // GB
  }
}

class ChineseModelInstaller {
  private models: ChineseModel[] = [
    {
      name: "qwen2.5:0.5b",
      displayName: "Qwen2.5 0.5B",
      description: "è¶…è½»é‡çº§ä¸­æ–‡æ¨¡å‹ï¼Œé€‚åˆèµ„æºå—é™ç¯å¢ƒ",
      size: "0.4GB",
      sizeGB: 0.4,
      category: "lightweight",
      chineseOptimized: true,
      codingCapability: "basic",
      priority: 1,
      recommended: true,
      requirements: {
        minRAM: 1,
        minDisk: 1,
        recommendedRAM: 2,
      },
    },
    {
      name: "qwen2.5:1.5b",
      displayName: "Qwen2.5 1.5B",
      description: "è½»é‡çº§ä¸­æ–‡ç¼–ç¨‹æ¨¡å‹ï¼Œå¹³è¡¡æ€§èƒ½ä¸èµ„æºæ¶ˆè€—",
      size: "0.9GB",
      sizeGB: 0.9,
      category: "lightweight",
      chineseOptimized: true,
      codingCapability: "good",
      priority: 2,
      recommended: true,
      requirements: {
        minRAM: 2,
        minDisk: 2,
        recommendedRAM: 4,
      },
    },
    {
      name: "qwen2.5:3b",
      displayName: "Qwen2.5 3B",
      description: "ä¸­ç­‰è§„æ¨¡ä¸­æ–‡æ¨¡å‹ï¼Œä¼˜ç§€çš„ä»£ç ç”Ÿæˆèƒ½åŠ›",
      size: "1.9GB",
      sizeGB: 1.9,
      category: "balanced",
      chineseOptimized: true,
      codingCapability: "excellent",
      priority: 3,
      recommended: true,
      requirements: {
        minRAM: 4,
        minDisk: 3,
        recommendedRAM: 6,
      },
    },
    {
      name: "qwen2.5:7b",
      displayName: "Qwen2.5 7B",
      description: "é«˜æ€§èƒ½ä¸­æ–‡ç¼–ç¨‹æ¨¡å‹ï¼Œä¸“ä¸šçº§ä»£ç ç”Ÿæˆ",
      size: "4.4GB",
      sizeGB: 4.4,
      category: "balanced",
      chineseOptimized: true,
      codingCapability: "excellent",
      priority: 4,
      recommended: true,
      requirements: {
        minRAM: 8,
        minDisk: 6,
        recommendedRAM: 12,
      },
    },
    {
      name: "qwen2.5:14b",
      displayName: "Qwen2.5 14B",
      description: "å¤§è§„æ¨¡ä¸­æ–‡æ¨¡å‹ï¼Œé¡¶çº§ç¼–ç¨‹å’Œæ¨ç†èƒ½åŠ›",
      size: "8.2GB",
      sizeGB: 8.2,
      category: "powerful",
      chineseOptimized: true,
      codingCapability: "excellent",
      priority: 5,
      recommended: false,
      requirements: {
        minRAM: 16,
        minDisk: 10,
        recommendedRAM: 24,
      },
    },
    {
      name: "qwen2.5-coder:1.5b",
      displayName: "Qwen2.5-Coder 1.5B",
      description: "ä¸“é—¨çš„ä¸­æ–‡ä»£ç ç”Ÿæˆæ¨¡å‹ï¼Œè½»é‡é«˜æ•ˆ",
      size: "0.9GB",
      sizeGB: 0.9,
      category: "lightweight",
      chineseOptimized: true,
      codingCapability: "excellent",
      priority: 6,
      recommended: true,
      requirements: {
        minRAM: 2,
        minDisk: 2,
        recommendedRAM: 4,
      },
    },
    {
      name: "qwen2.5-coder:7b",
      displayName: "Qwen2.5-Coder 7B",
      description: "ä¸“ä¸šä¸­æ–‡ä»£ç ç”Ÿæˆæ¨¡å‹ï¼Œæ”¯æŒå¤šç§ç¼–ç¨‹è¯­è¨€",
      size: "4.4GB",
      sizeGB: 4.4,
      category: "balanced",
      chineseOptimized: true,
      codingCapability: "excellent",
      priority: 7,
      recommended: true,
      requirements: {
        minRAM: 8,
        minDisk: 6,
        recommendedRAM: 12,
      },
    },
    {
      name: "deepseek-coder:1.3b",
      displayName: "DeepSeek-Coder 1.3B",
      description: "è½»é‡çº§ä»£ç ä¸“ç”¨æ¨¡å‹ï¼Œæ”¯æŒä¸­æ–‡æ³¨é‡Š",
      size: "0.7GB",
      sizeGB: 0.7,
      category: "lightweight",
      chineseOptimized: true,
      codingCapability: "excellent",
      priority: 8,
      recommended: false,
      requirements: {
        minRAM: 2,
        minDisk: 1,
        recommendedRAM: 3,
      },
    },
    {
      name: "deepseek-coder:6.7b",
      displayName: "DeepSeek-Coder 6.7B",
      description: "é«˜æ€§èƒ½ä»£ç ç”Ÿæˆæ¨¡å‹ï¼Œä¼˜ç§€çš„ä¸­æ–‡ç¼–ç¨‹èƒ½åŠ›",
      size: "3.8GB",
      sizeGB: 3.8,
      category: "balanced",
      chineseOptimized: true,
      codingCapability: "excellent",
      priority: 9,
      recommended: false,
      requirements: {
        minRAM: 8,
        minDisk: 5,
        recommendedRAM: 10,
      },
    },
  ]

  private logFile: string
  private installationLog: string[] = []

  constructor() {
    this.logFile = `./logs/chinese-models-install-${new Date().toISOString().slice(0, 10)}.log`
    this.ensureLogDirectory()
  }

  // ç¡®ä¿æ—¥å¿—ç›®å½•å­˜åœ¨
  private async ensureLogDirectory(): Promise<void> {
    try {
      if (!existsSync("./logs")) {
        await mkdir("./logs", { recursive: true })
      }
    } catch (error) {
      console.warn("åˆ›å»ºæ—¥å¿—ç›®å½•å¤±è´¥:", error)
    }
  }

  // è®°å½•æ—¥å¿—
  private log(message: string, level: "info" | "warn" | "error" = "info"): void {
    const timestamp = new Date().toISOString()
    const logMessage = `[${timestamp}] [${level.toUpperCase()}] ${message}`

    console.log(logMessage)
    this.installationLog.push(logMessage)

    // å†™å…¥æ–‡ä»¶
    try {
      const stream = createWriteStream(this.logFile, { flags: "a" })
      stream.write(logMessage + "\n")
      stream.end()
    } catch (error) {
      // å¿½ç•¥æ–‡ä»¶å†™å…¥é”™è¯¯
    }
  }

  // æ£€æŸ¥ç³»ç»Ÿèµ„æº
  private async checkSystemResources(): Promise<{
    totalRAM: number
    availableRAM: number
    availableDisk: number
  }> {
    try {
      // æ£€æŸ¥å†…å­˜
      const memInfo = execSync("free -g", { encoding: "utf-8" })
      const memLines = memInfo.split("\n")
      const memLine = memLines[1].split(/\s+/)
      const totalRAM = Number.parseInt(memLine[1]) || 8 // é»˜è®¤8GB
      const availableRAM = Number.parseInt(memLine[6]) || 4 // é»˜è®¤4GB

      // æ£€æŸ¥ç£ç›˜ç©ºé—´
      const diskInfo = execSync("df -BG .", { encoding: "utf-8" })
      const diskLines = diskInfo.split("\n")
      const diskLine = diskLines[1].split(/\s+/)
      const availableDisk = Number.parseInt(diskLine[3].replace("G", "")) || 10 // é»˜è®¤10GB

      return { totalRAM, availableRAM, availableDisk }
    } catch (error) {
      this.log(`è·å–ç³»ç»Ÿèµ„æºä¿¡æ¯å¤±è´¥: ${error}`, "warn")
      // è¿”å›ä¿å®ˆä¼°è®¡å€¼
      return { totalRAM: 8, availableRAM: 4, availableDisk: 10 }
    }
  }

  // æ£€æŸ¥OllamaæœåŠ¡çŠ¶æ€
  private async checkOllamaService(): Promise<boolean> {
    try {
      const response = await fetch("http://localhost:11434/api/tags", {
        signal: AbortSignal.timeout(5000),
      })
      return response.ok
    } catch {
      return false
    }
  }

  // è·å–å·²å®‰è£…çš„æ¨¡å‹
  private getInstalledModels(): string[] {
    try {
      const output = execSync("ollama list", { encoding: "utf-8", stdio: "pipe" })
      const lines = output.split("\n").slice(1) // è·³è¿‡æ ‡é¢˜è¡Œ
      return lines
        .filter((line) => line.trim())
        .map((line) => line.split(/\s+/)[0])
        .filter((name) => name && name !== "NAME")
    } catch {
      return []
    }
  }

  // æ¨èæ¨¡å‹é€‰æ‹©
  private recommendModels(systemResources: {
    totalRAM: number
    availableRAM: number
    availableDisk: number
  }): ChineseModel[] {
    const { availableRAM, availableDisk } = systemResources
    const recommended: ChineseModel[] = []

    this.log(`ç³»ç»Ÿèµ„æº: RAM ${availableRAM}GB, ç£ç›˜ ${availableDisk}GB`)

    // æŒ‰ä¼˜å…ˆçº§æ’åº
    const sortedModels = [...this.models].sort((a, b) => a.priority - b.priority)

    let totalSize = 0
    for (const model of sortedModels) {
      // æ£€æŸ¥èµ„æºè¦æ±‚
      if (
        model.requirements.minRAM <= availableRAM &&
        model.requirements.minDisk + totalSize <= availableDisk * 0.8 // ä¿ç•™20%ç©ºé—´
      ) {
        recommended.push(model)
        totalSize += model.sizeGB

        // ä¼˜å…ˆå®‰è£…æ¨èæ¨¡å‹
        if (model.recommended && recommended.length >= 3) {
          break
        }
      }
    }

    return recommended
  }

  // æ˜¾ç¤ºæ¨¡å‹ä¿¡æ¯
  private displayModelInfo(): void {
    console.log("\nğŸ¤– ä¸­æ–‡ä¼˜åŒ–AIæ¨¡å‹åˆ—è¡¨")
    console.log("=" * 80)

    const categories = ["lightweight", "balanced", "powerful"]
    const categoryNames = {
      lightweight: "ğŸš€ è½»é‡çº§æ¨¡å‹ (é€‚åˆå¼€å‘æµ‹è¯•)",
      balanced: "âš–ï¸ å¹³è¡¡å‹æ¨¡å‹ (æ¨èç”Ÿäº§ä½¿ç”¨)",
      powerful: "ğŸ’ª å¼ºåŠ›æ¨¡å‹ (é«˜æ€§èƒ½éœ€æ±‚)",
    }

    for (const category of categories) {
      console.log(`\n${categoryNames[category as keyof typeof categoryNames]}:`)

      const categoryModels = this.models.filter((m) => m.category === category)
      for (const model of categoryModels) {
        const badge = model.recommended ? "â­" : "  "
        const chinese = model.chineseOptimized ? "ğŸ‡¨ğŸ‡³" : "  "
        const coding = model.codingCapability === "excellent" ? "ğŸ’»" : model.codingCapability === "good" ? "ğŸ“" : "ğŸ“„"

        console.log(
          `  ${badge}${chinese}${coding} ${model.displayName.padEnd(25)} ${model.size.padEnd(8)} ${model.description}`,
        )
        console.log(`      å†…å­˜éœ€æ±‚: ${model.requirements.minRAM}GB (æ¨è: ${model.requirements.recommendedRAM}GB)`)
      }
    }

    console.log("\nğŸ“– å›¾ä¾‹:")
    console.log("  â­ æ¨èå®‰è£…  ğŸ‡¨ğŸ‡³ ä¸­æ–‡ä¼˜åŒ–  ğŸ’» ä»£ç ä¸“å®¶  ğŸ“ ä»£ç è‰¯å¥½  ğŸ“„ ä»£ç åŸºç¡€")
  }

  // å®‰è£…å•ä¸ªæ¨¡å‹
  private async installModel(model: ChineseModel): Promise<boolean> {
    this.log(`å¼€å§‹å®‰è£…æ¨¡å‹: ${model.displayName} (${model.name})`)

    try {
      // åˆ›å»ºè¿›åº¦æ˜¾ç¤º
      console.log(`\nğŸ“¦ æ­£åœ¨å®‰è£…: ${model.displayName}`)
      console.log(`   å¤§å°: ${model.size}`)
      console.log(`   æè¿°: ${model.description}`)

      // ä½¿ç”¨spawnæ¥å®æ—¶æ˜¾ç¤ºè¿›åº¦
      const child = spawn("ollama", ["pull", model.name], {
        stdio: ["inherit", "pipe", "pipe"],
      })

      let output = ""
      let lastProgress = ""

      child.stdout?.on("data", (data) => {
        const text = data.toString()
        output += text

        // è§£æè¿›åº¦ä¿¡æ¯
        const lines = text.split("\n")
        for (const line of lines) {
          if (line.includes("pulling") || line.includes("downloading") || line.includes("%")) {
            if (line !== lastProgress) {
              process.stdout.write(`\r   ${line.trim()}`)
              lastProgress = line
            }
          }
        }
      })

      child.stderr?.on("data", (data) => {
        const text = data.toString()
        if (!text.includes("pulling") && !text.includes("downloading")) {
          console.error(`   é”™è¯¯: ${text}`)
        }
      })

      // ç­‰å¾…å®‰è£…å®Œæˆ
      const exitCode = await new Promise<number>((resolve) => {
        child.on("close", resolve)
      })

      if (exitCode === 0) {
        console.log(`\nâœ… ${model.displayName} å®‰è£…æˆåŠŸ`)
        this.log(`æ¨¡å‹å®‰è£…æˆåŠŸ: ${model.name}`)

        // æµ‹è¯•æ¨¡å‹
        await this.testModel(model)
        return true
      } else {
        console.log(`\nâŒ ${model.displayName} å®‰è£…å¤±è´¥ (é€€å‡ºç : ${exitCode})`)
        this.log(`æ¨¡å‹å®‰è£…å¤±è´¥: ${model.name}, é€€å‡ºç : ${exitCode}`, "error")
        return false
      }
    } catch (error) {
      console.log(`\nâŒ ${model.displayName} å®‰è£…å¼‚å¸¸`)
      this.log(`æ¨¡å‹å®‰è£…å¼‚å¸¸: ${model.name}, é”™è¯¯: ${error}`, "error")
      return false
    }
  }

  // æµ‹è¯•æ¨¡å‹
  private async testModel(model: ChineseModel): Promise<boolean> {
    console.log(`ğŸ§ª æµ‹è¯•æ¨¡å‹: ${model.displayName}`)

    try {
      const testPrompts = ["ä½ å¥½ï¼Œè¯·ç”¨ä¸€å¥è¯ä»‹ç»è‡ªå·±", "ç”¨Pythonå†™ä¸€ä¸ªHello Worldç¨‹åº", "è§£é‡Šä»€ä¹ˆæ˜¯é€’å½’ç®—æ³•"]

      const randomPrompt = testPrompts[Math.floor(Math.random() * testPrompts.length)]

      const response = await fetch("http://localhost:11434/api/generate", {
        method: "POST",
        headers: {
          "Content-Type": "application/json",
        },
        body: JSON.stringify({
          model: model.name,
          prompt: randomPrompt,
          stream: false,
        }),
        signal: AbortSignal.timeout(30000), // 30ç§’è¶…æ—¶
      })

      if (response.ok) {
        const data = await response.json()
        if (data.response && data.response.length > 10) {
          console.log(`âœ… æ¨¡å‹æµ‹è¯•æˆåŠŸ`)
          console.log(`   æé—®: ${randomPrompt}`)
          console.log(`   å›ç­”: ${data.response.substring(0, 100)}...`)
          this.log(`æ¨¡å‹æµ‹è¯•æˆåŠŸ: ${model.name}`)
          return true
        }
      }
    } catch (error) {
      this.log(`æ¨¡å‹æµ‹è¯•å¤±è´¥: ${model.name}, é”™è¯¯: ${error}`, "warn")
    }

    console.log(`âš ï¸ æ¨¡å‹æµ‹è¯•æœªé€šè¿‡ï¼Œä½†å®‰è£…å¯èƒ½æˆåŠŸ`)
    return false
  }

  // é…ç½®ç¯å¢ƒå˜é‡
  private configureEnvironment(installedModels: string[]): void {
    console.log("\nğŸ”§ ç¯å¢ƒé…ç½®å»ºè®®:")
    console.log("=" * 50)

    // æ¨èé»˜è®¤æ¨¡å‹
    const defaultModel = installedModels.find((m) => m.includes("qwen2.5:1.5b")) || installedModels[0]

    if (defaultModel) {
      console.log(`å»ºè®®è®¾ç½®é»˜è®¤æ¨¡å‹: ${defaultModel}`)
      console.log(`åœ¨ .env.local ä¸­æ·»åŠ :`)
      console.log(`NEXT_PUBLIC_DEFAULT_MODEL=${defaultModel}`)
    }

    // æ˜¾ç¤ºæ‰€æœ‰å·²å®‰è£…çš„ä¸­æ–‡æ¨¡å‹
    console.log(`\nå·²å®‰è£…çš„ä¸­æ–‡ä¼˜åŒ–æ¨¡å‹:`)
    installedModels.forEach((model, index) => {
      console.log(`  ${index + 1}. ${model}`)
    })
  }

  // ç”Ÿæˆä½¿ç”¨æŒ‡å—
  private generateUsageGuide(installedModels: string[]): void {
    console.log("\nğŸ“š ä½¿ç”¨æŒ‡å—:")
    console.log("=" * 40)

    console.log("1. ä»£ç ç”Ÿæˆç¤ºä¾‹:")
    console.log(`   curl -X POST http://localhost:11434/api/generate \\`)
    console.log(`     -H "Content-Type: application/json" \\`)
    console.log(`     -d '{`)
    console.log(`       "model": "${installedModels[0] || "qwen2.5:1.5b"}",`)
    console.log(`       "prompt": "ç”¨Pythonå†™ä¸€ä¸ªå¿«é€Ÿæ’åºç®—æ³•ï¼Œæ·»åŠ ä¸­æ–‡æ³¨é‡Š",`)
    console.log(`       "stream": false`)
    console.log(`     }'`)

    console.log("\n2. åœ¨DeepStackä¸­ä½¿ç”¨:")
    console.log("   - è®¿é—®: http://localhost:3000/modules/deepstack-generator")
    console.log("   - é€‰æ‹©ä¸­æ–‡ä¼˜åŒ–æ¨¡å‹")
    console.log("   - è¾“å…¥ç¼–ç¨‹éœ€æ±‚ï¼Œè·å¾—ä¸­æ–‡æ³¨é‡Šçš„ä»£ç ")

    console.log("\n3. æ¨¡å‹æ€§èƒ½å¯¹æ¯”:")
    installedModels.forEach((model) => {
      const modelInfo = this.models.find((m) => m.name === model)
      if (modelInfo) {
        console.log(`   ${model}:`)
        console.log(
          `     - é€‚ç”¨åœºæ™¯: ${modelInfo.category === "lightweight" ? "å¿«é€Ÿå¼€å‘" : modelInfo.category === "balanced" ? "ç”Ÿäº§ç¯å¢ƒ" : "é«˜æ€§èƒ½éœ€æ±‚"}`,
        )
        console.log(`     - ä»£ç èƒ½åŠ›: ${modelInfo.codingCapability}`)
        console.log(`     - å†…å­˜éœ€æ±‚: ${modelInfo.requirements.recommendedRAM}GB`)
      }
    })
  }

  // ä¸»å®‰è£…æµç¨‹
  public async install(): Promise<void> {
    console.log("ğŸ¤– ä¸­æ–‡ä¼˜åŒ–AIæ¨¡å‹å®‰è£…å™¨")
    console.log("=" * 60)
    console.log("ä¸“ä¸ºä¸­æ–‡ç¼–ç¨‹å’ŒDeepStackä¼˜åŒ–")

    this.log("å¼€å§‹ä¸­æ–‡æ¨¡å‹å®‰è£…æµç¨‹")

    // 1. æ£€æŸ¥OllamaæœåŠ¡
    console.log("\nğŸ” æ£€æŸ¥ç³»ç»Ÿç¯å¢ƒ...")
    const isOllamaRunning = await this.checkOllamaService()
    if (!isOllamaRunning) {
      console.log("âŒ OllamaæœåŠ¡æœªè¿è¡Œ")
      console.log("è¯·å…ˆå¯åŠ¨OllamaæœåŠ¡:")
      console.log("  ollama serve")
      this.log("OllamaæœåŠ¡æœªè¿è¡Œï¼Œå®‰è£…ä¸­æ­¢", "error")
      return
    }
    console.log("âœ… OllamaæœåŠ¡æ­£å¸¸")

    // 2. æ£€æŸ¥ç³»ç»Ÿèµ„æº
    const systemResources = await this.checkSystemResources()
    console.log(`âœ… ç³»ç»Ÿèµ„æºæ£€æŸ¥å®Œæˆ`)
    console.log(`   å†…å­˜: ${systemResources.availableRAM}GB å¯ç”¨ / ${systemResources.totalRAM}GB æ€»è®¡`)
    console.log(`   ç£ç›˜: ${systemResources.availableDisk}GB å¯ç”¨`)

    // 3. è·å–å·²å®‰è£…æ¨¡å‹
    const installedModels = this.getInstalledModels()
    console.log(`ğŸ“¦ å·²å®‰è£…æ¨¡å‹: ${installedModels.length}ä¸ª`)

    // 4. æ˜¾ç¤ºå¯ç”¨æ¨¡å‹
    this.displayModelInfo()

    // 5. æ¨èæ¨¡å‹
    const recommendedModels = this.recommendModels(systemResources)
    console.log(`\nğŸ¯ æ ¹æ®æ‚¨çš„ç³»ç»Ÿé…ç½®ï¼Œæ¨èå®‰è£…ä»¥ä¸‹æ¨¡å‹:`)

    let totalSize = 0
    recommendedModels.forEach((model, index) => {
      totalSize += model.sizeGB
      console.log(`   ${index + 1}. ${model.displayName} (${model.size})`)
      console.log(`      ${model.description}`)
    })
    console.log(`ğŸ“Š æ€»è®¡å¤§å°: ${totalSize.toFixed(1)}GB`)

    // 6. è¿‡æ»¤æœªå®‰è£…çš„æ¨¡å‹
    const modelsToInstall = recommendedModels.filter((model) => !installedModels.includes(model.name))

    if (modelsToInstall.length === 0) {
      console.log("\nâœ… æ‰€æœ‰æ¨èçš„ä¸­æ–‡æ¨¡å‹å·²å®‰è£…")
      this.configureEnvironment(installedModels.filter((m) => this.models.some((model) => model.name === m)))
      this.generateUsageGuide(installedModels.filter((m) => this.models.some((model) => model.name === m)))
      return
    }

    console.log(`\nğŸš€ å‡†å¤‡å®‰è£… ${modelsToInstall.length} ä¸ªæ–°æ¨¡å‹...`)

    // 7. å¼€å§‹å®‰è£…
    const results: Array<{ model: ChineseModel; success: boolean }> = []

    for (const model of modelsToInstall) {
      const success = await this.installModel(model)
      results.push({ model, success })

      // å®‰è£…é—´éš”
      if (modelsToInstall.indexOf(model) < modelsToInstall.length - 1) {
        console.log("\nâ³ ç­‰å¾…2ç§’åç»§ç»­...")
        await new Promise((resolve) => setTimeout(resolve, 2000))
      }
    }

    // 8. å®‰è£…ç»“æœç»Ÿè®¡
    const successful = results.filter((r) => r.success).length
    const failed = results.filter((r) => !r.success).length

    console.log("\nğŸ“Š å®‰è£…ç»“æœç»Ÿè®¡:")
    console.log("=" * 40)
    console.log(`âœ… æˆåŠŸå®‰è£…: ${successful}ä¸ª`)
    console.log(`âŒ å®‰è£…å¤±è´¥: ${failed}ä¸ª`)

    if (successful > 0) {
      console.log("\nâœ… æˆåŠŸå®‰è£…çš„æ¨¡å‹:")
      results
        .filter((r) => r.success)
        .forEach((r) => {
          console.log(`   âœ“ ${r.model.displayName} - ${r.model.description}`)
        })
    }

    if (failed > 0) {
      console.log("\nâŒ å®‰è£…å¤±è´¥çš„æ¨¡å‹:")
      results
        .filter((r) => !r.success)
        .forEach((r) => {
          console.log(`   âœ— ${r.model.displayName}`)
        })
    }

    // 9. é…ç½®å’Œä½¿ç”¨æŒ‡å—
    const allInstalledModels = this.getInstalledModels()
    const chineseModels = allInstalledModels.filter((m) => this.models.some((model) => model.name === m))

    if (chineseModels.length > 0) {
      this.configureEnvironment(chineseModels)
      this.generateUsageGuide(chineseModels)
    }

    // 10. å®Œæˆæç¤º
    console.log("\nğŸ‰ ä¸­æ–‡ä¼˜åŒ–æ¨¡å‹å®‰è£…å®Œæˆ!")
    console.log("\nğŸš€ ä¸‹ä¸€æ­¥:")
    console.log("   1. è®¿é—® DeepStack ä»£ç ç”Ÿæˆå™¨")
    console.log("   2. é€‰æ‹©ä¸­æ–‡ä¼˜åŒ–æ¨¡å‹")
    console.log("   3. å¼€å§‹æ™ºèƒ½ç¼–ç¨‹ä¹‹æ—…!")

    this.log("ä¸­æ–‡æ¨¡å‹å®‰è£…æµç¨‹å®Œæˆ")
  }
}

// å¦‚æœç›´æ¥è¿è¡Œæ­¤è„šæœ¬
if (require.main === module) {
  const installer = new ChineseModelInstaller()
  installer.install().catch((error) => {
    console.error("å®‰è£…è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯:", error)
    process.exit(1)
  })
}

export { ChineseModelInstaller }
